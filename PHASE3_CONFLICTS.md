# Phase 3 - Potentiella Konflikter & L√∂sningar

**Skapad:** 2025-10-07  
**Status:** Granskning innan Phase 3 p√•b√∂rjas  
**Syfte:** Identifiera och planera f√∂r alla potentiella konflikter mellan befintlig infrastruktur och Phase 3-implementation

---

## üî¥ KRITISKA KONFLIKTER

### 1. Modell-fil Struktur Inkonsistens

**Problem:**
```
BTC & ETH: Multi-timeframe struktur
{
  "1m": {...},
  "5m": {...},
  "1h": {...}
}

ANDRA 14 SYMBOLER: Flat struktur (endast 1m implicit)
{
  "schema": [...],
  "buy": {...},
  "sell": {...}
}
```

**P√•verkan:**
- ML training scripts kommer beh√∂va hantera B√ÖDA strukturer
- ModelRegistry har redan fallback-logik (line 72-82) MEN:
  - Flat struktur har ingen timeframe-info
  - Training m√•ste veta vilken struktur som ska anv√§ndas
  - Risk f√∂r att skriva fel format

**L√∂sning:**
```markdown
Priority: KRITISKT - Innan ML training

1. Migrera alla 14 flat-strukturer till multi-timeframe:
   ```bash
   python scripts/migrate_model_structure.py --all
   ```

2. Skapa migration script:
   - L√§s flat JSON
   - Wrap i {"1m": <flat_content>}
   - Kopiera till andra timeframes (5m, 15m, 1h, 4h, 1D)
   - Beh√•ll Git history (rename ‚Üí edit)

3. Validera:
   - K√∂r alla tester
   - Verifiera ModelRegistry laddar korrekt
   - Test med alla symbols √ó alla timeframes
```

**Risk om ej √•tg√§rdat:**
- Training script kraschar eller skriver fel format
- Inkonsistent data mellan symbols
- Sv√•rt att debugga

---

### 2. ModelRegistry Cache Invalidation

**Problem:**
```python
# model_registry.py line 48-56
cached = self._cache.get(key)
if cached and abs(cached[1] - mtime) < 1e-6:
    return cached[0]  # ‚Üê PROBLEM!
```

**Scenario:**
```
1. Bot l√§ser tBTCUSD.json ‚Üí cached
2. ML training uppdaterar tBTCUSD.json ‚Üí ny mtime
3. Bot k√∂r pipeline ‚Üí cache hit (mtime diff < 1Œºs?)
4. Bot anv√§nder GAMLA vikter! ‚ùå
```

**P√•verkan:**
- Training-resultat syns inte i live bot
- A/B testing blir felaktigt
- Champion deployment tar inte effekt

**L√∂sning:**
```python
Priority: H√ñGT - Innan ML deployment

1. F√∂rb√§ttra cache invalidation:
   ```python
   # √ñka precision eller anv√§nd hash
   if cached and stat.st_mtime == cached[1]:
       return cached[0]
   ```

2. Eller: Force reload efter training:
   ```python
   # I train_model.py efter save
   ModelRegistry()._cache.clear()
   ```

3. L√§gg till explicit reload-endpoint:
   ```python
   # server.py
   @app.post("/models/reload")
   def reload_models():
       ModelRegistry()._cache.clear()
       return {"ok": True}
   ```
```

**Test:**
```bash
1. Starta bot
2. K√∂r pipeline ‚Üí Result A
3. Uppdatera model fil manuellt
4. K√∂r pipeline igen ‚Üí Result B (ska vara olika!)
```

---

### 3. Data Directory Missing

**Problem:**
```
data/ directory existerar inte
‚îî‚îÄ‚îÄ Beh√∂vs f√∂r:
    ‚îú‚îÄ‚îÄ candles/
    ‚îú‚îÄ‚îÄ features/
    ‚îî‚îÄ‚îÄ metadata/
```

**P√•verkan:**
- Historical fetcher kraschar
- Ingen plats att spara data
- Git ignorerar inte data-filer

**L√∂sning:**
```markdown
Priority: H√ñGT - Innan data fetch

1. Skapa directory structure:
   ```bash
   mkdir -p data/{candles,features,metadata}
   ```

2. Uppdatera .gitignore:
   ```gitignore
   # Data files
   data/candles/*.parquet
   data/features/*.parquet
   data/metadata/*.json
   
   # Beh√•ll README
   !data/README.md
   !data/**/README.md
   ```

3. Skapa data/README.md:
   ```markdown
   # Genesis-Core - Data Directory
   
   ## Structure
   - candles/: Historical OHLCV data (Parquet)
   - features/: Pre-computed features (Parquet)
   - metadata/: Data quality reports (JSON)
   
   ## NOT IN GIT
   Data files are not version controlled due to size.
   Use scripts/fetch_historical.py to download.
   ```
```

---

## üü° MEDEL KONFLIKTER

### 4. Bitfinex Rate Limiting

**Problem:**
```python
# Bitfinex Candles API limits (VERIFIED):
# Source: https://docs.bitfinex.com/reference/rest-public-candles
- 30 requests / minute (candles endpoint specific)
- Historical data: max 10,000 candles/request
- 6 months @ 1m = ~262,800 candles ‚Üí 27 requests
```

**P√•verkan:**
```
Fetch 6 months √ó 5 timeframes √ó 2 symbols = 270 requests
‚Üí 9 minuter minimum (med 30 req/min)
‚Üí Managed med rate limiter
```

**L√∂sning:**
```python
Priority: MEDIUM - Innan mass fetch

1. Implementera rate limiter i fetch_historical.py:
   ```python
   from ratelimit import limits, sleep_and_retry
   
   @sleep_and_retry
   @limits(calls=27, period=60)  # 27/min (s√§kerhetsmarginal fr√•n 30)
   def fetch_candles_page(...):
       ...
   ```

2. Progress tracking:
   ```python
   from tqdm import tqdm
   
   for symbol in tqdm(symbols):
       for tf in tqdm(timeframes):
           fetch_with_retry(symbol, tf)
   ```

3. Retry logic med exponential backoff:
   ```python
   @retry(
       stop=stop_after_attempt(3),
       wait=wait_exponential(multiplier=1, min=4, max=60)
   )
   def fetch_with_retry(...):
       ...
   ```
```

**Fallback:**
```python
# Om rate limit √§nd√• tr√§ffas:
# Spara progress ‚Üí pause 60s ‚Üí forts√§tt
metadata = {
    "last_fetched": "tBTCUSD_5m",
    "progress": "40%",
    "timestamp": "2025-10-07T12:00:00Z"
}
```

---

### 5. Training Overwriting Production Models

**Problem:**
```python
# train_model.py uppdaterar direkt:
with open("config/models/tBTCUSD.json", "w") as f:
    json.dump(new_model, f)  # ‚Üê √ñverskriver LIVE model!
```

**P√•verkan:**
- Otestade modeller g√•r live direkt
- Ingen A/B testing m√∂jlig
- Sv√•rt att rulla tillbaka

**L√∂sning:**
```python
Priority: MEDIUM - Innan f√∂rsta tr√§ning

1. Anv√§nd versioning:
   ```python
   # Spara som ny version f√∂rst
   output = f"config/models/tBTCUSD_v{version}.json"
   with open(output, "w") as f:
       json.dump(new_model, f)
   ```

2. Champion selection process:
   ```python
   # Manuell review innan deployment
   python scripts/select_champion.py \
     --baseline config/models/tBTCUSD.json \
     --candidate config/models/tBTCUSD_v2.json \
     --backtest-period 2024-09-01:2024-10-01
   
   # Om b√§ttre ‚Üí deploy
   # Om s√§mre ‚Üí beh√•ll baseline
   ```

3. Git workflow:
   ```bash
   # Branch f√∂r training
   git checkout -b train/btc-v2
   # Train & commit
   git add config/models/tBTCUSD_v2.json
   git commit -m "feat: trained BTC model v2"
   # Review ‚Üí merge om godk√§nd
   ```
```

---

### 6. Feature Schema Changes

**Problem:**
```python
# Nuvarande models: ["ema_delta_pct", "rsi"]
# Om vi l√§gger till fler features i training:
# ‚Üí Old models inte kompatibla
```

**P√•verkan:**
- Gamla modeller kraschar med nya features
- Eller nya modeller saknar features
- Version conflict

**L√∂sning:**
```python
Priority: MEDIUM - Innan feature expansion

1. Strict schema validation:
   ```python
   def validate_features(features, model_schema):
       required = set(model_schema)
       available = set(features.keys())
       missing = required - available
       if missing:
           raise ValueError(f"Missing features: {missing}")
   ```

2. Feature version in model:
   ```json
   {
     "1m": {
       "schema": ["ema_delta_pct", "rsi"],
       "schema_version": "v1",  ‚Üê NY!
       "buy": {...}
     }
   }
   ```

3. Backward compatibility:
   ```python
   # Om model kr√§ver v2 men vi har v1:
   # ‚Üí Ber√§kna extra features on-the-fly
   # ‚Üí Eller refuse to load
   ```
```

---

## üü¢ MINDRE KONFLIKTER

### 7. Disk Space f√∂r Parquet Files

**Problem:**
```
6 months @ 1m = 262,800 rows
√ó 6 columns (OHLCV + timestamp)
√ó 8 bytes (float64)
= ~12 MB per symbol/timeframe (uncompressed)

16 symbols √ó 6 timeframes = 96 files
√ó 12 MB = 1.15 GB
```

**L√∂sning:**
- Parquet compression ‚Üí ~200-400 MB
- Acceptabelt f√∂r development
- Production: anv√§nd cloud storage

---

### 8. Pandas Import Performance

**Problem:**
```python
import pandas as pd  # ‚Üê 200-500ms f√∂rsta g√•ngen
```

**P√•verkan:**
- Server startup latency
- Testing blir l√•ngsammare

**L√∂sning:**
```python
# Lazy import i backtest/training:
def run_backtest(...):
    import pandas as pd  # ‚Üê Only n√§r backtest k√∂rs
    ...

# INTE i pipeline-kod (beh√•ller 0.6ms latency)
```

---

### 9. Test Symbols vs Real Symbols

**Problem:**
```python
# Paper trading: tTESTBTC:TESTUSD
# Historical data: tBTCUSD
# Models: tBTCUSD
```

**P√•verkan:**
- Confusion mellan test/real symbols
- Fel symbol i training

**L√∂sning:**
```python
# Tydlig namngivning:
# DATA:   tBTCUSD (real market data)
# MODEL:  tBTCUSD (trained on real data)
# PAPER:  tTESTBTC:TESTUSD (test execution)

# Symbol mapping finns redan i SymbolMapper
```

---

### 10. Concurrent Model Updates

**Problem:**
```
Bot l√§ser model ‚Üí Training skriver model ‚Üí Race condition
```

**L√∂sning:**
```python
# Atomic writes:
import tempfile
import os

def save_model_atomic(path, data):
    with tempfile.NamedTemporaryFile(
        mode='w', 
        dir=path.parent, 
        delete=False
    ) as f:
        json.dump(data, f)
        temp_path = f.name
    os.replace(temp_path, path)  # Atomic p√• POSIX
```

---

## üìã PRE-PHASE3 CHECKLIST

**Innan du b√∂rjar Phase 3, g√∂r:**

- [ ] **Migrera alla modeller till multi-timeframe struktur**
  - Script: `scripts/migrate_model_structure.py`
  - Validera: K√∂r alla tester
  - Commit: `feat: migrate all models to multi-timeframe structure`

- [ ] **F√∂rb√§ttra ModelRegistry cache invalidation**
  - Fixa mtime-check eller anv√§nd hash
  - Test: Manuell model update ‚Üí verify reload
  - Commit: `fix: improve model cache invalidation`

- [ ] **Skapa data directory structure**
  - `mkdir -p data/{candles,features,metadata}`
  - Uppdatera `.gitignore`
  - Skapa `data/README.md`
  - Commit: `chore: setup data directory structure`

- [ ] **Implementera rate limiter**
  - Install: `pip install ratelimit tenacity`
  - Base utility: `src/core/utils/rate_limit.py`
  - Commit: `feat: add rate limiting utility`

- [ ] **Review och dokumentera**
  - L√§s igenom TODO_PHASE3.md
  - L√§s igenom denna fil (PHASE3_CONFLICTS.md)
  - Diskutera om n√•got √§r oklart

---

## üîÑ KONFLIKT-L√ñSNINGS PRIORITET

```
1. KRITISKT (Innan Phase 3):
   ‚úÖ Migrera model struktur
   ‚úÖ Fixa cache invalidation
   ‚úÖ Skapa data directories

2. H√ñGT (Innan f√∂rsta tr√§ning):
   ‚úÖ Rate limiting
   ‚úÖ Versioning workflow
   ‚úÖ Schema validation

3. MEDIUM (Kan fixas under Phase 3):
   ‚ö†Ô∏è Feature schema changes
   ‚ö†Ô∏è Disk space planning
   ‚ö†Ô∏è Lazy imports

4. L√ÖGT (Nice-to-have):
   ‚óã Concurrent update handling
   ‚óã Cloud storage integration
```

---

## üéØ SAMMANFATTNING

**Totalt identifierade konflikter:** 10  
**Kritiska:** 3  
**Medel:** 3  
**Mindre:** 4  

**Estimated resolution time:**
- Kritiska: 4-6 timmar
- Medel: 4-6 timmar
- Mindre: 2-3 timmar
**Total: 1-2 arbetsdagar**

**Rekommendation:**
L√∂s alla kritiska konflikter INNAN Phase 3 p√•b√∂rjas.
Detta sparar tid och f√∂rhindrar problem senare.

**Status:** ‚úÖ Redo att b√∂rja resolution

---

**N√§sta steg:**
1. Skapa `scripts/migrate_model_structure.py`
2. K√∂r migration
3. K√∂r alla tester
4. Forts√§tt med n√§sta kritiska konflikt
